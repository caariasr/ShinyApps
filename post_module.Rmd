---
title: "Big data post module assignment"
author: "CADMS"
date: "6/18/2017"
output:
  html_document:
    code_folding: hide
    highlight: kate
    keep_md: yes
    theme: readable
    toc: yes
runtime: shiny
resource_files:
- bigdata.Rproj
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# source('/gridapps/hive/HIVERJARS/connect2hive.R')
```

```{r packages, include=FALSE, message=FALSE}
library(knitr)
library(shiny)
library(highr)
library(base64enc)
library(png)
library(ggvis)
library(plyr)
library(dplyr)
library(ggmap)
library(zipcode)
```
##Introduction
The Big Data post module assignment provides an opportunity to learn how to interact with hive, how to understand and clean multiple databases, how to merge the disparate data into one database, and finally how to analyze the data to draw conclusions and make correlations. This R Markdown document depicts Team CADMS' efforts to take advantage of this learning opportunity by creating an interactive narrative of the step-by-step process followed since the post module period began. The initial steps included accessing, understanding, and cleaning the data, followed by filtering the data to merge it into a single analyzable database. The final step was to conduct analysis and create visualizations to understand connections and correlations present in the data.

In this report we will be analyzing data from the 311 Calls, restaurant violations, housing violations and the population by zip code. The information is provided for New York city and for the year 2016. 

All the files are allocated in the Stern big data cluster in the Hive MSBA database. The files have the following names:

| Description                             | Table Name        |
| ----------------------------------------|:----------------- |
|311 Calls for 2016                       |NYC311calls2016    |
|Restaurant Violations (all years)        |nycrestaurants     |
|Housing Violations (all years)           |housingviolations  |
|Population by Zip code (all US for 2010)  |popbyzip2010       |

Throughout the document, the reader will find **in bold** difficulties we encounter during the process.

##Hypotesis

There are correlations between 311 calls, housing violations, restaurants and population in New York City

##Procedure

1. Data Understanding 
2. Data Cleaning Process.
3. Data Merging Process
    +Creation of Data Views
    +Data Aggregation and Merge
4. Visualizations and Correlation analysis.
5. Conclusions.



##Data Understanding


This initial step in this process is to understand every single field in all data base. The data is divided into four separate data tables. Each data table must to be reviewed for data clarity and consistency. Below is the step-by-step approach for data understanding:

  1. For every table we have built a data dictionary where we describe the following for each attribute.

    + Data type
    + Description
    + Problems with the data
    + Solutions to the problems with the data
    + The type to which the variable should be converted.
    
    The data dictionary is located in the following [link.](https://docs.google.com/spreadsheets/d/1JmR_Ltpbqzho_SWPS-0K1CfEyaVPVwluhBMAzfY7sNM/edit?usp=sharing)

**Analyzing and Understanding the Files/Tables**

Restaurant Violations (all years)  - nycrestaurants

This files is composed of 19 attributes that describe the restaurant violations for the boroughs of Brookling, Bronx, Manhattan, Queens and Staten Island. The table contains all the attributes that identify each restaurant along with the details of the violations.

FINDINGS:

+ For 824 records there is no violation code. They are the result of an inspection that concluded with : "No violations were recorded at the time of this inspection.". Therefore, we need to erase these records from the files since they do not represent any violation. 

+ 209 records do not have information in the following fields: dba (name of the restaurant), cuisine_description, inspection_date, action, violation_code, violation_description, critical_flag, score, grade, grade_date, and inspection_type. These records were deleted.


Population by Zip code (all US for 2010) - popbyzip2010

This file contains the the population for all the zip codes in the US for the year 2010. Even though the analysis is for the year 2016, the population of the year 2010 is a close proxy.

FINDINGS:

+ The main issue with the zip codes is that for some of them we only have 4 digits, when all zip codes must have 5 digits. The way to correct this was to simply add a "0" at the beginning of the record.

+ We only took into account the zip codes for the boroughs addressed by the other tables.

+ For some records the population is '0'. The explanation is not that the records is wrong, it simply indicates that in that specific zip code there are no residencies.


Housing Violations (all years) - housingviolations

This file contains the housing violation history for the boroughs of Brookling, Bronx, Manhattan, Queens and Staten Island. The records clearly states when the inspection was made, the address of the place and the description of the violation followed by the current status. It is worth to mention that this file has most of the records with consistent information, and we did not find issues while processing the information. 


311 Calls for 2016 - NYC311calls2016

This file contains all the 311 calls received in NYC for the year 2016. The zip code that this table provides is not for the location of the call but the location of the incident. this becomes important when we will be analyzing the correlation among all four tables. Some of the records show that there was in fact no incident or that it was not possible to perform the inspection. However, we are going to keep these records since our interest in to find the relation to the fact that there was a call in place. 

FINDINGS:

+ Among all files, this is the only one that provides the geo location of the reported incident. 

+ The detail for each incident is more than what we need in our analysis, so we are going to discard most of the fields that cant be correlated with the other files. This will make this table lighter and easier to analyze.

**External tables added to the analysis**

At this point we realized that we wanted to also include visualization with maps where we could place all kinds of violations. In order to use such tools we needed to find a way to find the geo location for all zip codes to be analyzed. The only file that provided such information was the 311, so we needed to add a table with the geo location for all other zip codes. We used the package "zipcode", and we called it using the command > data("zipcode")



**Dificulties: The first issue was to find a way to confortably filter and overview the data in order find the singularities within each field, empty values, typos, incomplete values and incorrect formats. The way we solved this problem was to create tables and views where the values were unique. After using filters and sorting tools we could easily find all problematic values.**


##Data Cleaning Process

The first step of the data cleaning process was to create the team database in hive and to move the tables from the `msba` database into it.

The second step focused on cleaning the data under zip code in all three tables. Some of the zip codes had incorrect formatting, such as additional digits and symbols. The symbols were removed and the first five digits were extracted as "true" zip codes. Subsequently the zip codes were converted to numbers and filtered to only include those in New York City.

The NYC 311 calls were restricted by location type of violation to initially include: restaurant, residential, family, and private house. However, further inspection into the 311 call files revealed that other types of location should be included, namely, apartment and residence. As for the restaurant violation files, the following were added for filtration: bars, clubs, bakery, deli, cafeteria, catering, food cart, and soup kitchen. The new approach is meant to broaden the selection process and hence improve the accuracy of the results.

The location type data had formatting issues such as: the same word written in lower and upper cases. Same location mentioned more than once in different formats and groups i.e. residential and residential/House. There are N/As and mixed used housing (residential and none). All these issues had to be identified and fixed by unifying the data. 

Some columns were incorrectly labeled and therefore the columns were re-labeled based on the data it contained. This was observed in the following columns: `x_coordinate_state_plane`, `y_coordinate_state_plane`, `borough`, `longitude`, `latitude`, `location`, and `junk`.

Some cities were mentioned multiple times as unique instances, in lower case and upper case. i.e. Astoria vs. ASTORIA. Some cities were described with more than one unique identifier i.e. BELLEROSE vs. BELLEROSE VILLAGE. Some cities were misspelled i.e. CEDARHURST vs. CEDERHURST. One field was missing data.

The restaurant violations and housing violations files were restricted to year 2016 given that the NYC 311 calls file covered only the year of 2016.

`created_date` was selected as a variable from the NYC 311 calls and the `inspection_date` in both restaurant and housing violations files were chosen to match that date. At a later check, the "Inspection Date" was replaced by `record_date` as it preceded inspection and better matched "Created Date".

The column `month` was created for all tables except population, by substrating the first two characters of the corresponding date column.

## Data Merging Process

### Creation of Data Views
The initial step in the data merging process centered on the creation of multiple views of each database filtered and grouped by relevant variables. The relevant variables were determined using the knowledge gained from the data understanding and data cleaning processes. A total of five views were created during this step, they include:

* View 1 labeled `restaurantcallsbyzipmonth` referenced the nyc311callscleaned database to filter `restaurant_calls` by `location_type` to include locations with strings that had the words "restaurant", "soup", "catering", "food", and "cafateria". Once this filter was applied to the `restaurant_calls`, the data was then grouped by zipcode and month.

* View 2 labeled `housingcallsbyzipmonth` referenced the nyc311callscleaned database to filter `housing_calls` by `location_type` to include locations with strings that had the words "residential", "family", "private house", "apartment", and "residence". Once this filter was applied to the `housing_calls`, the data was then grouped by zipcode and month.

* View 3 labeled `criticalsbyzipmonth` referenced the nycrestaurantscleaned database to filter `restaurant_critical_violations` by `iscritical` to include only the violations that are "critical". Once this filter was applied to the `restaurant_critical_violations`, the data was then grouped by zipcode and month.

* View 4 labeled `restaurantsbyzipmonth` referenced the nycrestaurantscleaned database to group by zipcode and month.

* View 5 labeled `housingbyzipmonth` referenced the housingcleaned database to group by zipcode and month.

### Data Aggregation and Merge
Following the creation of the five views in the step above, the next step consisted of data aggregation. The data aggregation step included the creation of a new database labeled `allbyzipmonth` witch joined the five views created in the previous step with the nycpopbyzip database. The merge process joined each of the five views by zipcode and month. In addition to creating the `allbyzipmonth` database, a `allbyzip` database was also created using the same process detailed above. Both databases were used to conduct data analysis, witch will be described in the next section.

### Initial analysis

### Connect to database CADMS
Here we connect to our database
```{r connect, eval=FALSE}
# conn = dbConnect(drv,"jdbc:hive2://bigdata.stern.nyu.edu:10000/cadms;auth=noSasl","","")
```
### Bring the views into R for visualizations

```{r get views, message=FALSE}
#allbyzipmonth <- dbGetQuery(conn, "select * from allbyzipmonth")
#saveRDS(allbyzipmonth, file="data/allbyzipmonth.rds")
#allbyzipmonth <- read.table("data/allbyzipmonth.txt", sep = "\t", header=T)
allbyzipmonth <- readRDS("data/allbyzipmonth.rds")
allbyzipmonth$month <- mapvalues(allbyzipmonth$month, 1:12, month.name) 

allbyzipmonth$month <- factor(allbyzipmonth$month, levels = month.name)
head(allbyzipmonth)
```

## Visualizations
### Housing
```{r houseVis, fig.height=5, fig.width=15, retina=1, message=FALSE}
allbyzipmonth %>% 
    ggvis(x=~housing_calls, y=~housing_violations) %>%
    filter(allbyzipmonth$month %in% 
             eval(input_checkboxgroup(choices=month.name, 
                                      selected = month.name, label = "Month"))) %>% 
    layer_points(fill = ~factor(month)) %>%
    add_axis("x", title = "Number of 311 calls per zipcode") %>%
    add_axis("y", title = "Number of housing violations", 
             properties=axis_props(title=list(dy=-50))) %>%
    scale_numeric("x", domain = c(0, 4000), nice = FALSE) %>%
    scale_numeric("y", domain = c(0, 2000), nice = FALSE)
```

**Initial conclusions**: The number of housing violations plotted against the number of 311 calls per zipcode behaves in a significantly linear fashion by month and in aggregate; as one would expect, an increase in the number of calls relates to an increase in housing violations. 

November and December do not have any reliable data points which could indicate that the city performs annual inspections or no inspections during this time, in lieu of inspections in response to 311 calls. October has consistently curious behavior over the course of this analysis in that it yields a low number of housing violations and a low number of 311 calls - this may be an error in the analysis process or a systemic factor of which the team does not have an understanding. 

### Restaurants
```{r resVis, fig.height=5, fig.width=15, retina=1}
allbyzipmonth %>% 
    ggvis(x=~restaurant_calls, y=~restaurant_violations) %>%
    filter(allbyzipmonth$month %in% 
             eval(input_checkboxgroup(choices=month.name, 
                                      selected = month.name, label = "Month"))) %>% 
    layer_points(fill = ~month) %>%
    add_axis("x", title = "Number of 311 calls per zipcode") %>%
    add_axis("y", title = "Number of restaurant violations") %>%
    scale_numeric("x", domain = c(0, 200), nice = FALSE) %>%
    scale_numeric("y", domain = c(0, 600), nice = FALSE)
```

**Initial conclusions:** The number of restaurant violations plotted against number of 311 calls per zipcode does not display a strong linear relationship  either in month or in aggregate. A separate view of the data by month does not deviate from this conclusion based on the aggregated months. One hypothesis that the group was testing was that environmental factors that motivate 311 calls may drive the number of restaurant violations but this does not appear to show within the data results. 


### Population and housing
```{r pophous, fig.height=5, fig.width=15, retina=1}
allbyzipmonth %>% 
    ggvis(x=~population, y=input_select(c("housing_calls", "housing_violations"), 
                                         label="Choose calls or violations",  
                                         map = as.name)) %>%
    filter(allbyzipmonth$month %in% 
             eval(input_checkboxgroup(choices=month.name, 
                                      selected = month.name, label = "Month"))) %>% 
    layer_points(fill = ~month) %>%
    add_axis("x", title = "Population", properties=axis_props(title=list(dy=-50))) %>%
    add_axis("y", title = "Number of housing calls/violations", 
             properties=axis_props(title=list(dy=-50))) %>%
    scale_numeric("x", domain = c(0, 110000), nice = T) %>%
    scale_numeric("y", domain = c(0, 3000), nice = T)
```

**Initial conclusions:** The number of housing calls (and separately violations) plotted against number of 311 calls per zip code shows some differences by months/seasons. Excluding October, which shows drastically different behavior than the other months and November and December which do not have any data, January-April tend to have  less concentrated data sets while May-September are more concentrated. There are many more zip codes with higher instances of housing calls and violations in the winter/spring - perhaps due to seasonality and corresponding utility effects . This relationship appears to have potential for further exploration.

### Population and restaurants
```{r popres, fig.height=5, fig.width=15, retina=1}
allbyzipmonth %>% 
    ggvis(x=~population, y=input_select(c("restaurant_calls", "restaurant_violations"), 
                                         label="Choose calls or violations",  
                                         map = as.name)) %>%
    filter(allbyzipmonth$month %in% 
             eval(input_checkboxgroup(choices=month.name, 
                                      selected = month.name, label = "Month"))) %>% 
    layer_points(fill = ~month) %>%
    add_axis("x", title = "Population", properties=axis_props(title=list(dy=-50))) %>%
    add_axis("y", title = "Number of restaurant calls/violations", 
             properties=axis_props(title=list(dy=-50)))
```

**Initial conclusions:** Population and the number of restaurant calls shows the same banding of seasonality as in 'population and housing.' Winter/spring months tend to show looser groupings with higher maximums than do summer/fall months with a global observation of maximums decreasing after Population 60,000.

Restaurant violations plotted against population do not show the same pattern but do also have some slight differences in the maximum values with the winter/spring months being higher, to a less drastic degree than the number of calls


### Analysis by zipcode only

We went back to hive and created aggregated views by zipcode only, we then merged by zipcode and
loaded the view here.
```{r load data }
# allbyzip <- dbGetQuery(conn, "select * from cadms.allbyzip")
# saveRDS(allbyzip, file="data/allbyzip.rds")
# allbyzip <- read.table('data/allbyzip.txt', sep="\t", header=T)
allbyzip <- readRDS("data/allbyzip.rds")
head(allbyzip)
```

## Visualizations by zipcode only
Since we found that the violations don’t occur in the last two months (November had one sum instance and December 0). We decided to create another joined table - only by zipcode because we believe that a significant amount of calls were not matching just because they occurred in the last two months of the year.

### Restaurant calls and violations
An initial question of interest for the analysis is: Is there a linear 
relation between the number of 311 calls for restaurants and the number of
violations per month per zip code?

```{r correlations}
cor(allbyzip$restaurant_calls, allbyzip$restaurant_violations)
```
The correlation between restaurant 311 calls and violations is `r round(cor(allbyzip$restaurant_calls, allbyzip$restaurant_violations), 2)`. It would be a good idea to go back to the location_type used to filter the 311 calls specific about restaurants and see if there were some missing categories that could be included as restaurants. Assuming there is no missing calls counted
as 311 restaurant calls, we can conclude that there is not a strong linear relationship between restaurant 311 calls and violations. Nevertheless we can test the null hypothesis that the population's true linear relationship is zero:

```{r test correlation}
cor.test(allbyzip$restaurant_calls, allbyzip$restaurant_violations)
```

The p-value for the correlation test is less than 2.2e-16 so we reject the null hypothesis 
that the true linear correlation between 311 calls and violations for restaurants is zero.

### Housing calls and violations
The same question applies to the relationship between housing calls and violations:
```{r housing cor}
cor(allbyzip$housing_violations, allbyzip$housing_calls)
```
The correlation is `r round(cor(allbyzip$housing_violations, allbyzip$housing_calls), 2)`. 
In this case, there is a strong linear relationship between calls and violations for housing.

### Correlation matrix

```{r all cors}
cor(allbyzip[, -1])
```

Finally we produce a correlation matrix to look for any other linear relationship between our variables. We can see that the population has a linear relationship with the housing calls 
(`r round(cor(allbyzip$population, allbyzip$housing_calls), 2)`).

### Housing
```{r houseVis2, fig.height=5, fig.width=15, retina=1}
allbyzip %>% 
    ggvis(x=~housing_calls, y=~housing_violations) %>%
    layer_points() %>%
    add_axis("x", title = "Number of 311 calls per zipcode") %>%
    add_axis("y", title = "Number of housing violations",
             properties=axis_props(title=list(dy=-30)))
```

**Initial conclusions:** As with the truncated dataset from the earlier analysis, there is a strong linear relationship between the number of 311 calls by zipcode plotted against the number of housing violations. The effects of heteroscedasticity are present and expected because we are working with data of count type. 

### Restaurants
```{r resVis2, fig.height=5, fig.width=15, retina=1}
allbyzip %>% 
    ggvis(x=~restaurant_calls, y=~restaurant_violations) %>%
    layer_points() %>%
    add_axis("x", title = "Number of 311 calls per zipcode") %>%
    add_axis("y", title = "Number of restaurant violations", 
             properties=axis_props(title=list(dy=-30)))
```

**Initial conclusions:** No change from the previous analysis - there is a very weak linear relationship between the number of 311 calls per zipcode and the number of restaurant violations.

### Population and housing
```{r housepopVis, fig.height=5, fig.width=15, retina=1}
allbyzip %>% 
    ggvis(x=~population, y=input_select(c("housing_calls", "housing_violations"), 
                                         label="Choose calls or violations",  
                                         map = as.name)) %>%
    layer_points() %>%
    add_axis("x", title = "Population") %>%
    add_axis("y", title = "Calls/Violations", properties=axis_props(title=list(dy=-30))) %>%
    scale_numeric("x", domain = c(0, 110000), nice = T) %>%
    scale_numeric("y", domain = c(0, 26000), nice = T)
```

**Initial conclusions:** Similar to other visualizations by zipcode only, there was little change from earlier analysis. Housing violations vs population by zip code appear to have a more dispersed data set than housing calls vs. population by zip code and stay true to previous observations.

### Population and restaurants
```{r respopVis, fig.height=5, fig.width=15, retina=1}
allbyzip %>% 
    ggvis(x=~population, y=input_select(c("restaurant_calls", "restaurant_violations"), 
                                         label="Choose calls or violations",  
                                         map = as.name)) %>%
    layer_points() %>%
    add_axis("x", title = "Population") %>%
    add_axis("y", title = "Calls/Violations", properties=axis_props(title=list(dy=-30))) %>%
    scale_numeric("x", domain = c(0, 110000), nice = T) %>%
    scale_numeric("y", domain = c(0, 4500), nice = T)
```

**Initial conclusions:** Restaurant calls and violations have a relationship with population, with restaurant violations being much more dispersed than calls. This may indicate a set of missing data or error in data transformation, as we do not expect to see such a stark difference in correlation between the two attributes. 

### Maps
#### Housing violations

```{r housemaps, message=FALSE, message=FALSE}
data("zipcode")
names(zipcode)[1] <- "zipcode"
allcoordzip <- merge(zipcode, allbyzip)
rm(zipcode)
# get map
map<-get_map(location='New York City',maptype = "terrain", source='google')
ggmap(map) + geom_point(
        aes(x=longitude, y=latitude, colour=housing_violations), 
        data=allcoordzip, alpha=1, na.rm = T)  + 
        scale_color_gradient(low="green", high="red")
```

**Initial conclusions:** The heatmap indicates that most housing violations occur in the Bronx, Harlem, and Brooklyn. In the next heatmap iteration, it may be useful to change the ranges of heatmap color indications to have better visibility of housing violations below 5,000.

#### Restaurant violations
```{r resmaps, message=FALSE, message=FALSE}
# get map
map<-get_map(location='New York City',maptype = "terrain", source='google')
ggmap(map) + geom_point(
        aes(x=longitude, y=latitude, colour=restaurant_violations), 
        data=allcoordzip, alpha=1, na.rm = T)  + 
        scale_color_gradient(low="green", high="red")
```

**Initial conclusions:** Lower Manhattan has the highest density of restaurant violations, followed distantly by portions of Brooklyn and Harlem.

##Conclusion
**DRAFT** 
(need to wait for intro and final edits to the above before finalizing the conclusion, the below are just thoughts)
The Big Data post module assignment provides an opportunity to learn how to interact with hive, how to understand and clean multiple databases, how to merge disparate data into one database, and finally how to analyze the data inorder to draw conclusions and make correlations. This R Markdown document depicts Team CADMS' efforts to take advantage of this learning opportunity by creating an interactive narrative of the step-by-step process followed since the post module period began. The initial steps inlcuded accessing, understanding, and cleaning the data, followed by filtering the data to merge it into a single analyzable database. The final step was to cunduct analysis and create visualizations to understand connections and correlations present in the data.

